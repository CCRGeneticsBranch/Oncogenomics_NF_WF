{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#introduction","title":"Introduction","text":"<p>This bioinformatics pipeline is containerized and platform-independent, built using a Nextflow DSL2 workflow, and deployed on both the NIH Biowulf HPC cluster and the AWS cloud.  </p> <p>This Exome\u2013RNA-seq workflow accepts a samplesheet and FASTQ files as input, then performs a comprehensive set of analyses, including:  </p> <ul> <li>Extensive quality control  </li> <li>Mutation calling  </li> <li>Tumor mutational burden assessment  </li> <li>Mutational signature analysis  </li> <li>HLA typing  </li> <li>Copy-number variation detection  </li> <li>T-cell infiltration prediction  </li> <li>Neoantigen prediction  </li> <li>Gene expression profiling  </li> <li>Fusion detection  </li> <li>Variant calling and annotation  </li> </ul> <p>This end-to-end suite supports deep genomic characterization for both research and institutional datasets at NIH.  </p> <p>Results can be explored via the ClinOmics Data Portal, which provides a secure, interactive, user friendly web interface for data visualization and interpretation. It is well suited for both individual patient level and cohort wide cancer genomics analysis.</p>"},{"location":"#who-this-is-for","title":"Who This Is For","text":"<p>This workflow is intended for researchers and bioinformaticians working with exome and RNA-seq datasets who need a reproducible, scalable, and validated solution for comprehensive genomic analysis. It is designed for use in both HPC and cloud computing environments.  </p> <p>Here is a Snapshot of our RNAseq and Exome workflows.</p>"},{"location":"#rnaseq-workflow-dag","title":"RNAseq Workflow DAG","text":""},{"location":"#exome-workflow-dag","title":"Exome Workflow DAG","text":""},{"location":"#workflow-tools","title":"Workflow Tools","text":"RNA-seq ToolsExome ToolsCommon Tools Stage Tool(s) Purpose Alignment STAR Align RNA-seq reads to the reference genome with splice-aware mapping Strandedness Assessment ngsderive Determine library strandedness from aligned BAM files Expression Quantification RSEM Quantify gene and transcript abundance Post-mapping QC Picard CollectRNASeqMetrics, RNA-SeQC Evaluate mapping quality, insert size, and gene body coverage BAM Processing GATK SplitNCigarReads, RealignerTargetCreator, IndelRealigner, BaseRecalibrator, PrintReads Prepare RNA-seq BAMs for variant calling by handling spliced reads, realigning indels, and recalibrating base quality scores Variant Calling GATK HaplotypeCaller Identify germline SNPs and indels from RNA-seq data Fusion Detection STAR-Fusion, Arriba, FusionCatcher Detect gene fusions; integrate consensus calls across multiple tools HLA Calling HLA-HD, OptiType Predict HLA types from RNA-seq data Variant Annotation ANNOVAR Annotate variants with functional consequences and external database references Stage Tool(s) Purpose Alignment BWA-MEM Align exome reads to the reference genome BAM QC Picard CollectAlignmentSummaryMetrics, Picard CollectInsertSizeMetrics Evaluate mapping quality, duplication rates, and insert size BAM Processing GATK MarkDuplicates, BaseRecalibrator, ApplyBQSR Mark duplicates, recalibrate base quality scores, and prepare BAMs for variant calling Germline Variant Calling GATK HaplotypeCaller Identify germline SNVs and indels Somatic Variant Calling Manta, Strelka2, GATK Mutect2 Identify somatic SNVs and indels Copy Number Calling CNVkit Detect copy number alterations Variant Annotation ANNOVAR, SnpEff, VEP Annotate variants with functional consequences and external database references T-cell Infiltration Estimation TcellExTRECT Estimate tumor-infiltrating T-cell abundance from sequencing data Tumor Ploidy &amp; Cellularity Sequenza Infer tumor purity and ploidy Microsatellite Instability MANTIS Detect microsatellite instability from tumor/normal pairs Mutational Signatures SigProfilerExtractor, COSMIC Signature Database Identify mutational signatures present in the tumor genome HLA Typing HLA-HD, OptiType Predict HLA types from sequencing data Neoantigen Prediction pVACseq Predict candidate neoantigens from tumor-specific variants Concordance Analysis Conpair Verify tumor/normal sample pairing via genotype concordance Stage Tool(s) Purpose Quality Control FastQC, MultiQC Assess raw read quality and generate aggregated QC reports Contamination Screening Kraken2, Krona, FastQ Screen Identify potential contamination from non-target species Read Trimming Cutadapt Remove adapters, low-quality bases, and trim reads for improved alignment BAM QC &amp; Coverage Analysis samtools, bamUtils, mpileup, bedtools Generate hotspot coverage plots, transcript coverage plots, circos plots, and perform BAM compression/clean-up QC Aggregation MultiQC Aggregate QC metrics across all steps into a single interactive report <p>Before You Begin</p> <p>If you are setting up this workflow for the first time, ensure your environment meets all prerequisites and dependencies. See the Prerequisites section below and If you are new to Nextflow, please refer to this page for quick introduction.</p>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>To run this workflow, you will need the following software:</p> <pre><code>    Nextflow &gt;= 21.04.3\n    Singularity 3.10.5\n    Graphviz 2.40\n</code></pre>"},{"location":"#architecture","title":"Architecture","text":"<ol> <li>The workflow is located in the Khanlab space: <code>/data/khanlab/projects/Nextflow_dev/dev/AWS_POC_MVP_NF</code>.</li> <li> <p>The <code>biowulf_nextflow.config</code> file in this directory contains the master configuration. A <code>config/</code> subfolder contains additional configuration files:</p> <pre><code>config/\n\u251c\u2500\u2500 aws_cluster_test.config\n\u251c\u2500\u2500 aws_ec2_test.config\n\u251c\u2500\u2500 aws_params.config\n\u251c\u2500\u2500 biowulf_cluster_test.config\n\u251c\u2500\u2500 biowulf_s3_test_params.config\n\u251c\u2500\u2500 biowulf_singularity.config\n\u251c\u2500\u2500 biowulf_small_test_params.config\n\u251c\u2500\u2500 biowulf_small_test_params_hg38.config\n\u251c\u2500\u2500 docker.config\n\u251c\u2500\u2500 GRCm39.config\n\u2514\u2500\u2500 omics.config\n</code></pre> </li> <li> <p>Pipeline can be launched using the script launch.sh. It takes samplesheet.csv as a mandatory input. </p> </li> <li>Guidelines to create an input samplesheet can be found here.</li> <li>All the references, annotation and bed files are currently located under <code>/data/khanlab</code>. We currently support data processing for these capture kits.</li> </ol>"},{"location":"#sequencing-capture-kits","title":"Sequencing capture kits","text":"RNAseq Exome Access clin_ex_v1 PolyA seqcapez.hu.ex.v3 PolyA_stranded Agilent_v7 Ribozero idt_v2_plus smartrna xgen_hyb_panelv2 seqcapez_hu_ex_v3 <p>If you want to process the data sequenced by other kits, please reach out to Vineela Gangalapudi.</p>"},{"location":"dockers/","title":"Dockers","text":"<p>On Biowulf, this pipeline is executed by first loading the Singularity and Nextflow modules. The pipeline itself utilizes Docker containers for processing data across its various subworkflows and processes.</p>"},{"location":"dockers/#docker-containers-used-in-the-pipeline","title":"Docker Containers Used in the Pipeline","text":""},{"location":"dockers/#nci-docker-containers","title":"NCI Docker Containers","text":"Tool/Process Container Path Cutadapt <code>nciccbr/ncigb_cutadapt_v1.18:latest</code> Fastqc <code>nciccbr/ccrgb_qctools:latest</code> Star., Rsem., Arriba, Starfusion <code>nciccbr/ccrgb_starplus:latest</code> Fusioncatcher <code>nciccbr/ccrgb_fusioncatcher:v2.0</code> Multiqc.* <code>nciccbr/ccbr_multiqc_1.9:v0.0.1</code> Picard.*, HSMetrics, Hotspot_Coverage, Hotspot_Boxplot, Flagstat, Bamutils, Merge_new_HLA, MergeHLA, Read_depth, FailedExons_Genes, Combine_variants, Merge_Pvacseq_vcf <code>nciccbr/ccrgb_qctools:latest</code> GATK.*, RNAseq_HaplotypeCaller, Exome_HaplotypeCaller <code>nciccbr/ccrgb_gatk_3.8-1:v1.0</code> Genotyping, HotspotPileup, Mutect_order, MutationalSignature, CoveragePlot, Exome_QC, CircosPlot, CircosPlot_lib, Mergefusion, Allstepscomplete, RNAlibrary_customQC, RNAqc_TrancriptCoverage, CoveragePlot, Coverage, Lib2_RNAqc_TrancriptCoverage, TargetIntervals, CNVkit_png, Strelka_vcf_processing <code>nciccbr/ccrgb_qctools:latest</code> AddAnnotation., Split_vcf, UnionSomaticCalls, Actionable., DBinput.*, Sequenza_annot, MutationBurden, Expressed <code>nciccbr/ccrgb_qctools:latest</code> Mixcr <code>nciccbr/ccrgb_mixcr:v1.1</code> VDJtools <code>nciccbr/ccrgb_vdjtools:latest</code> Bamutil <code>nciccbr/ccrgb_bamutil:latest</code> SnpEff <code>nciccbr/ccrgb_snpeff:1.0</code> Vcf2txt, FormatInput.*, Annovar, Custom_annotation, Combine_annotation <code>nciccbr/ccrgb_annovar:v1.0</code> RNAseQC <code>nciccbr/ccrgb_rnaseqc_v1.1.8:latest</code> Strandedness <code>nciccbr/ccbr_ngsderive:v1.0</code> BWA <code>nciccbr/ccbr_ubuntu_base_20.04:v2.0</code> Sequenza <code>nciccbr/ccrgb_qctools:v3.2</code> Cosmic3Signature <code>nciccbr/ccrgb_qctools:v4.0</code> Fastq_screen <code>nciccbr/ccbr_fastq_screen_0.14.1:latest</code> TcellExtrect.* <code>hsienchao/tcell_extrect:v1</code> HLA_HD <code>vinegang/ccrgb_hlahd_1.7.0:v1.0</code> Conpair.* <code>nciccbr/ccrgb_conpair:latest</code> Fusion_Annotation, Merge_fusion_annotation <code>hsienchao/fusion_tools:v1</code> VEP <code>dnousome/ccbr_vcf2maf:v102.0.0</code> Pvacseq <code>vinegang/pvactools_1.3.5_ps:1.0</code> Mantis_MSI <code>vinegang/mantis:v1.0.5</code>"},{"location":"dockers/#non-nci-docker-containers","title":"Non-NCI Docker Containers","text":"Tool/Process Container Path Kraken <code>staphb/kraken:1.1.1-no-db</code> Krona <code>pbelmann/krona:latest</code> Bam2tdf <code>quay.io/biocontainers/igvtools:2.3.93--0</code> Optitype <code>fred2/optitype:release-v1.3.1</code> VerifyBamID <code>ottov/verifybamid-aws:latest</code> CNVkitP.* <code>zlskidmore/cnvkit:0.9.6</code> Mutect <code>dinglab2/mutect-tool:20190313</code> Manta <code>szarate/manta:v1.6.0</code> Strelka <code>davelabhub/strelka:2.9.10--0</code> Sequenza_utils <code>nkrumm/sequenza-nf:latest</code> CUSTOM_DUMPSOFTWAREVERSIONS <code>quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0</code>"},{"location":"pipeline_launch/","title":"Running the workflow.","text":"<p>This page explains what gets written where, how to monitor runs on Biowulf, how to resume or recover failed tasks, and what to collect when reporting errors.</p>"},{"location":"pipeline_launch/#results-directory-layout","title":"Results &amp; Directory Layout:","text":"<p>${OUTDIR} is the results root \u2014 either the default location or the custom path you provide when launching the workflow.</p> Files Path Results root <code>${OUTDIR}/${PATIENT}/${CASENAME}/</code> NXF state <code>${OUTDIR}/${PATIENT}/${CASENAME}/.nextflow/</code> Run logs (stdout) <code>${OUTDIR}/${PATIENT}/${CASENAME}/*.out</code> Nextflow reports (timeline, trace, manifest) <code>${OUTDIR}/${PATIENT}/${CASENAME}/log/</code> Nextflow workdir <code>${OUTDIR}/${PATIENT}/${CASENAME}/work/</code>"},{"location":"pipeline_launch/#sample-log-file","title":"Sample log file:","text":"<pre><code>[+] Loading singularity  4.0.3  on cn4280\n[+] Loading java 17.0.3.1  ...\n[+] Loading nextflow  23.10.0\n[+] Loading Graphviz v 2.46.1  ...\nNXF_HOME=/data/khanlab/projects/Nextflow_dev/dev/NCI0439/TestTNR/.nextflow\nnextflow run -c /vf/users/khanlab/projects/Nextflow_dev/dev/AWS_POC_MVP_NF/nextflow.config -profile biowulf_test_run_slurm --logdir /data/khanlab/projects/Nextflow_dev/dev/NCI0439/TestTNR/log /vf/users/khanlab/projects/Nextflow_dev/dev/AWS_POC_MVP_NF/main.nf -resume -with-trace -with-timeline -with-dag\nESC[33mNextflow 24.04.4 is available - Please consider updating your version to itESC(BESC[m\nN E X T F L O W  ~  version 23.10.0\nLaunching `/vf/users/khanlab/projects/Nextflow_dev/dev/AWS_POC_MVP_NF/main.nf` [shrivelled_stallman] DSL2 - revision: b8c8cd72d2\nE X O M E - R N A S E Q - N F   P I P E L I N E\n===================================\nNF version   : 23.10.0\nrunName      : shrivelled_stallman\nusername     : gangalapudiv2\nconfigs      : [/vf/users/khanlab/projects/Nextflow_dev/dev/AWS_POC_MVP_NF/nextflow.config, /vf/users/khanlab/projects/Nextflow_dev/dev/AWS_POC_MVP_NF/nextflow.config]\nprofile      : biowulf_test_run_slurm\ncmd line     : nextflow run -c /vf/users/khanlab/projects/Nextflow_dev/dev/AWS_POC_MVP_NF/nextflow.config -profile biowulf_test_run_slurm --logdir /data/khanlab/projects/Nextflow_dev/dev/NCI0439/TestTNR/log /vf/users/khanlab/projects/Nextflow_dev/dev/AWS_POC_MVP_NF/main.nf -resume -with-trace -with-timeline -with-dag\nstart time   : 2024-08-20T12:54:52.989621486-04:00\nprojectDir   : /vf/users/khanlab/projects/Nextflow_dev/dev/AWS_POC_MVP_NF\nlaunchDir    : /vf/users/khanlab/projects/Nextflow_dev/dev/NCI0439/TestTNR\nworkdDir     : /vf/users/khanlab/projects/Nextflow_dev/dev/NCI0439/TestTNR/work\nhomeDir      : /home/gangalapudiv2\n\n[-        ] process &gt; Tumor_Normal_RNAseq_WF:Comm... -\n[-        ] process &gt; Tumor_Normal_RNAseq_WF:Comm... -\n[-        ] process &gt; Tumor_Normal_RNAseq_WF:Comm... -\n[-        ] process &gt; Tumor_Normal_RNAseq_WF:Comm... -\n[-        ] process &gt; Tumor_Normal_RNAseq_WF:Comm... -\n</code></pre>"},{"location":"pipeline_launch/#debugging-where-to-look","title":"Debugging: Where to look","text":""},{"location":"pipeline_launch/#1-start-with-the-runs-stdout","title":"1) Start with the run\u2019s stdout","text":"<p>Check the Biowulf/Slurm stdout files for a quick overview and the exact work directory of the failed process:</p> <ul> <li><code>${OUTDIR}/${PATIENT}/${CASENAME}/*.out</code></li> </ul> <p>These files usually contain the error summary and a line like <code>work/&lt;hash&gt;</code> pointing to the failing task\u2019s work dir.</p>"},{"location":"pipeline_launch/#2-inspect-per-process-work-directory-logs","title":"2) Inspect per-process work-directory logs","text":"<p>For any failed task, open the work directory reported above and examine:</p> <pre><code>    work/&lt;hash&gt;/.command.sh\n    work/&lt;hash&gt;/.command.out\n    work/&lt;hash&gt;/.command.err\n    work/&lt;hash&gt;/.command.log\n</code></pre> <p>These files contain in-depth details of the process error (command, stdout, stderr, and Nextflow\u2019s execution log).</p>"},{"location":"pipeline_launch/#reporting-pipeline-issues","title":"Reporting pipeline issues","text":"<p>If the failure appears to be a code error or a pipeline glitch, please open a new issue with logs here</p>"},{"location":"references/","title":"Pipeline References & Tools","text":""},{"location":"references/#references","title":"References","text":"<p>This pipeline supports the human genome hg19 (GRCh37) and the mouse genome mm39 (GRCm39), using reference builds and annotations obtained from GENCODE.</p>"},{"location":"references/#hg19-grch37-resources","title":"hg19 (GRCh37) resources","text":"Component File Source Reference genome (FASTA) <code>GRCh37.primary_assembly.genome.fa.gz</code> ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/GRCh37_mapping/GRCh37.primary_assembly.genome.fa.gz Gene annotation (GTF) <code>gencode.v37lift37.annotation.gtf.gz</code> ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/GRCh37_mapping/gencode.v37lift37.annotation.gtf.gz <p>ERCC spike-in sequences were added to this reference (FASTA concatenated and indices rebuilt accordingly).</p>"},{"location":"references/#mm39-grcm39-resources","title":"mm39 (GRCm39) resources","text":"Component File Source Reference genome (FASTA) <code>GRCm39.primary_assembly.genome.fa.gz</code> https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M33/GRCm39.primary_assembly.genome.fa.gz Gene annotation (GTF) <code>gencode.vM33.primary_assembly.annotation.gtf.gz</code> https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M33/gencode.vM33.primary_assembly.annotation.gtf.gz"},{"location":"references/#tools-used","title":"Tools Used","text":"Tool Version Arriba 2.3.0 bwa 0.7.17-r1188 samtools 1.15.1 cnvkit 0.9.6 bedtools v2.27.1 Cutadapt 1.18 GATK 3.8-1-0-gf15c1c3ef Fastqc v0.11.9 Fusioncatcher 1.33 GATK 3.8-1-0-gf15c1c3ef bcftools 1.10.2 HLA-HD 1.7.0 Picard 2.27.4 Kraken 1.1.1 manta 1.6.0 multiqc 1.9 mutect 3.1-0-g72492bb Nextflow 23.10.0 Optitype v1.3.1 GATK 3.8-1-0-gf15c1c3ef samtools 1.10 RSEM v1.3.1 sequenza-utils 3.0.0 Snpsift 4.3t python 3.9.5 yaml 5.4.1 STAR 2.7.10a STAR-Fusion 1.11.1 strelka 2.9.10 vcftools 0.1.16 VEP 102.0 verifyBamID 1.1.3"},{"location":"results/","title":"Results","text":""},{"location":"results/#results","title":"Results","text":""},{"location":"samplesheet/","title":"Samplesheet","text":"<p>There are two ways to generate a samplesheet for the pipeline depending on the use case. If the goal is to process patient fastq files through the pipeline to use the results for secondary analysis, you can follow these steps to build your own samplesheet. Along with processing the data, if you want to visualize the results on ClinOmics data portal then follow steps to build samplesheet from mastersheet. This is highly recommended.</p>"},{"location":"samplesheet/#build-samplesheet-from-mastersheet","title":"Build samplesheet from mastersheet","text":"<p>For khanlab purposes, pipeline is always launched using the information in the mastersheets on biowulf under /data/khanlab space. The script samplesheet_builder.py queries the mastersheets to build a samplesheet for the pipeline. A copy of this script is available in the pipeline git repo. This script takes two inputs <code>PatientID</code> and <code>casename</code>. By default, it queries all mastersheets found in the <code>/data/khanlab/projects/DATA/Sequencing_Tracking_Master</code> directory and uses <code>/data/khanlab/projects/DATA</code> as the default input directory.</p> <p>When using a non-Khanlab master sheet, ensure the following columns are included:</p> <ul> <li>Patient ID: <code>PatientID</code></li> <li>Library ID: <code>LibraryID</code></li> <li>Enrichment Step: <code>Capture kit name</code></li> <li>Matched RNA-seq Library: <code>Matching RNA lib for the Exome library</code> (can be left empty)</li> <li>Matched Normal: <code>Matching normal lib for the Exome library</code> (can be left empty)</li> <li>Diagnosis: <code>Diagnosis</code></li> <li>Case Name: <code>casename for website</code></li> <li>Type: <code>Data type information</code></li> <li>FCID: <code>flowcell ID</code> (optional)</li> <li>Project: <code>Project name</code></li> </ul> <p>Read1, Read2 Construction: The script uses information from the Input directory and following columns to build the file paths for <code>read1</code> and <code>read2</code>.</p> <ul> <li>Library ID</li> <li>FCID (optional)   If FCID is provided, it will be used to build the paths; otherwise, the paths will be constructed using only the Input Path and Library ID.</li> </ul> <pre><code>Usage: python ./samplesheet_builder.py &lt;patient_id&gt; &lt;case_name&gt;\nDefault Samplesheet Directory: /data/khanlab/projects/DATA/Sequencing_Tracking_Master\nDefault Input Directory: /data/khanlab/projects/DATA\nTo use custom directories, modify the script:\n   - Change 'DEFAULT_SAMPLESHEET_DIR' to your samplesheet directory path\n   - Change 'DEFAULT_INPUT_DIR' to your input directory path\n</code></pre> <p><code>python ./samplesheet_builder.py Test_Patient casename</code> will output a file Test_Patient_casename.csv in the same folder.</p>"},{"location":"samplesheet/#error-handling","title":"Error Handling","text":"<p>The script includes the following error handling mechanisms:</p> <ul> <li>Invalid <code>read1</code> and <code>read2</code> Paths:   If the paths for <code>read1</code> and <code>read2</code> are invalid, the script will output an error message. This message will prompt you to check and verify the input paths.</li> </ul>"},{"location":"samplesheet/#build-your-own-samplesheet","title":"Build your own samplesheet","text":"<p>Alternately, we can build custom samplesheet without mastersheet. These are the required columns.</p> Column name Notes Example sample Patient name NCI-Test1 library Name of the sample library Test1_T1D_E read1 Full path to the read1 /data/khanlab/DATA/Sample_Test1_T1D_E/Sample_Test1_T1D_E.R1.fastq.gz read2 Full path to the read2 /data/khanlab/DATA/Sample_Test1_T1D_E/Sample_Test1_T1D_E.R2.fastq.gz sample_captures Name of the capture kit used List of supported capture kits are here Matched_RNA Matched RNA library for the tumor library. This includes cell_line_RNA and tumor_RNA Test1_T1R_T Matched_normal Matched exome normal library for the tumor library. This includes panel, blood DNA, cell_line_DNA Test1_N1D_E Diagnosis Diagnosis of the patient Glioma casename Casename for the patient NCI-Test1 type Data type example: tumor_RNA, tumor_DNA, normal_DNA, blood_DNA, cell_line_DNA, cell_line_RNA FCID Flowcell ID ACJ678349"},{"location":"samplesheet/#example-samplesheet","title":"Example samplesheet:","text":"<p>sample,library,read1,read2,sample_captures,Diagnosis,Matched_RNA,Matched_normal,casename,type,FCID,Project Test8,Test5_T1D_E,/data/khanlab/projects/fastq/Test5_T1D_E_R1.fastq.gz,/data/khanlab/projects/fastq/Test5_T1D_E_R2.fastq.gz,clin.ex.v1,Osteosarcoma,,Test8_N2D_E,NFtest0523,tumor_DNA,AWXYNH2,Test Test8,Test8_N2D_E,/data/khanlab/projects/fastq/Test8_N2D_E_R1.fastq.gz,/data/khanlab/projects/fastq/Test8_N2D_E_R2.fastq.gz,clin.ex.v1,Osteosarcoma,,,NFtest0523,normal_DNA,AWXYNH2,Test</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#usage","title":"Usage","text":"<p>This page describes how to run the workflow on Biowulf. For installation and prerequisites, see the Installation page.</p>"},{"location":"usage/#running-on-biowulf","title":"Running on Biowulf","text":"<p>On Biowulf, the pipeline is hosted in the Khanlab space. A helper script, <code>launch.sh</code>, is provided to simplify execution. This script wraps the <code>nextflow run</code> command with Biowulf-specific settings and automatically configures output directories, logging, and profiles.</p>"},{"location":"usage/#step-1-copy-the-launch-script","title":"Step 1 \u2014 Copy the launch script","text":"launch.sh <pre><code>#!/bin/bash\n\n# Set default values\nDEFAULT_OUTDIR=\"/data/khanlab/projects/processed_DATA\"\nDEFAULT_GENOME=\"hg19\"\nDEFAULT_PLATFORM=\"biowulf\"\n\n# Check if the required samplesheet argument is provided\nif [[ \"$#\" -lt 1 ]]; then\n    echo \"Usage: $0 &lt;samplesheet_with_full_path&gt; [output_directory] [genome]\"\n    echo \"This script requires at least one positional argument:\"\n    echo \"1. Path to samplesheet\"\n    echo \"Optional arguments:\"\n    echo \"2. Path to results directory (default: $DEFAULT_OUTDIR)\"\n    echo \"3. Genome name. Accepted values are hg19 and mm39 (default: $DEFAULT_GENOME)\"\n    exit 1\nfi\n\n# Assign the first argument (samplesheet) to a variable\nexport SAMPLESHEET=$1\n\n# Assign the second argument (output_directory) if provided, otherwise use the default\nexport OUTDIR=${2:-$DEFAULT_OUTDIR}\n\n# Assign the third argument (genome) if provided, otherwise use the default\nexport GENOME=${3:-$DEFAULT_GENOME}\n\nexport PLATFORM=${4:-$DEFAULT_PLATFORM}\n\n# Ensure the genome name is valid\nif [[ \"$GENOME\" != \"hg19\" &amp;&amp; \"$GENOME\" != \"mm39\" ]]; then\n    echo \"Invalid genome specified. Accepted values are hg19 and mm39.\"\n    exit 1\nfi\n\nWF_HOME=\"/data/khanlab/projects/Nextflow_dev/dev/AWS_POC_MVP_NF\"\nCONFIG_FILE=\"$WF_HOME/biowulf_nextflow.config\"\n\n#export PATIENT=$(awk -F',' 'NR==1 {for (i=1; i&lt;=NF; i++) if ($i==\"sample\") s=i} NR&gt;1 {print $s}' \"$SAMPLESHEET\" | sort | uniq)\n#export CASENAME=$(awk -F',' 'NR==1 {for (i=1; i&lt;=NF; i++) if ($i==\"casename\") c=i} NR&gt;1 {print $c}' \"$SAMPLESHEET\" | sort | uniq)\nexport PATIENT=$(python3 -c 'import csv,sys; r=csv.DictReader(open(sys.argv[1])); print(\"\\n\".join(sorted(set(row[\"sample\"] for row in r))))' \"$SAMPLESHEET\")\nexport CASENAME=$(python3 -c 'import csv,sys; r=csv.DictReader(open(sys.argv[1])); print(\"\\n\".join(sorted(set(row[\"casename\"] for row in r))))' \"$SAMPLESHEET\")\n\nexport RESULTSDIR=\"$OUTDIR/$PATIENT/$CASENAME\"\n\nmkdir -p \"$RESULTSDIR\"\n\nexport LOG=\"$RESULTSDIR/log\"\n\nmkdir -p \"$LOG\"\n\nexport NXF_HOME=\"$RESULTSDIR/.nextflow\"\n\nif [[ -z \"$PATIENT\" || -z \"$CASENAME\" ]]; then\n    echo \"Error: Could not extract PATIENT or CASENAME from the samplesheet.\"\n    exit 1\nfi\n\n\ncd $RESULTSDIR\n\nif [[ \"$GENOME\" == \"hg19\" ]]; then\n    PROFILE=\"biowulf_test_run_slurm\"\nelif [[ \"$GENOME\" == \"mm39\" ]]; then\n    PROFILE=\"biowulf_mouse_RNA_slurm\"\nelse\n    echo \"Unknown genome: $GENOME\"\n    exit 1\nfi\n\nlogname=$(basename \"$SAMPLESHEET\" .csv)\ntimestamp=$(date +\"%Y%m%d-%H%M%S\")\nsbatch &lt;&lt;EOT\n#!/bin/bash\n#SBATCH --job-name=\"$logname\"\n#SBATCH --output=\"$OUTDIR/$PATIENT/$CASENAME/${logname}_%A_${timestamp}.out\"\n#SBATCH --cpus-per-task=2\n#SBATCH --mem=05g\n#SBATCH --time=08-00:00:00\n\nmodule load nextflow/23.10.0 singularity graphviz\nnextflow run -c $CONFIG_FILE -profile $PROFILE --logdir $LOG $WF_HOME/main.nf -resume --samplesheet $SAMPLESHEET --resultsdir $OUTDIR --genome_v $GENOME --platform $PLATFORM\nexit 0\nEOT\n</code></pre> <p>Download or copy the script into your Biowulf working directory and make it executable:</p> <pre><code>cp /data/khanlab/projects/Nextflow_dev/dev/AWS_POC_MVP_NF/launch.sh .\nchmod +x launch.sh\n</code></pre>"},{"location":"usage/#step-2-view-usage-instructions","title":"Step 2 \u2014 View usage instructions","text":"<p>Run the script without arguments to display the usage help:</p> <pre><code>./launch.sh\n\nUsage: ./launch.sh &lt;samplesheet_with_full_path&gt; [output_directory] [genome]\nThis script requires at least one positional argument:\n1. Path to samplesheet\nOptional arguments:\n2. Path to results directory (default: /data/khanlab/projects/processed_DATA)\n3. Genome name. Accepted values are hg19 and mm39 (default: hg19)\n</code></pre> <p>Usage Examples:</p> <ol> <li> <p>Run with defaults (output to default path, genome hg19):</p> <p><code>./launch.sh /path/to/samplesheet.csv</code></p> </li> <li> <p>Run with custom output directory:</p> <p><code>./launch.sh /path/to/samplesheet.csv /custom/output/path</code></p> </li> <li> <p>Run with custom output directory and genome:</p> <p><code>./launch.sh /path/to/samplesheet.csv /custom/output/path mm39</code></p> </li> </ol> <p>mm39</p> <p>If mm39 is selected for the genome, the pipeline will run Mapping &amp; Gene expression only for mouse data.</p>"},{"location":"usage/#preparing-the-samplesheet","title":"Preparing the Samplesheet","text":"<p>You can prepare a samplesheet in two ways, depending on your use case:</p> <ol> <li>Build from a Master Sheet \u2013 Recommended if you also plan to visualize results in the ClinOmics Data Portal.  </li> <li>Build Manually \u2013 For standalone processing without portal integration.</li> </ol>"},{"location":"usage/#1-build-from-a-master-sheet-recommended","title":"1. Build from a Master Sheet (Recommended)","text":"<p>For Khanlab workflows, master sheets are stored on Biowulf in:</p> <p><code>/data/khanlab/projects/DATA/Sequencing_Tracking_Master</code></p> <p>Use the script:</p> <p>samplesheet_builder.py <pre><code>python ./samplesheet_builder.py &lt;PatientID&gt; &lt;CaseName&gt;\n</code></pre></p> <p>Default Master Sheet Directory: /data/khanlab/projects/DATA/Sequencing_Tracking_Master</p> <p>Default Input Directory: /data/khanlab/projects/DATA</p> <p>To use custom directories, edit DEFAULT_SAMPLESHEET_DIR and DEFAULT_INPUT_DIR in the script.</p> <p>Error Handling:</p> <ol> <li>Invalid FASTQ Paths \u2013 If <code>read1</code> or <code>read2</code> paths are invalid, the script will print an error prompting you to verify input paths.</li> <li>Unknown Capture Kit \u2013 If the capture kit entered is not listed in Sequencing Capture Kits, the script will assign <code>unknown</code> as the kit name.</li> </ol>"},{"location":"usage/#2-build-your-own-samplesheet","title":"2. Build Your Own Samplesheet","text":"<p>Create a CSV with these column information:</p> Column Description Example sample Patient name NCI-Test1 library Sample library name Test1_T1D_E read1 Path to R1 FASTQ /data/khanlab/DATA/Sample_Test1_T1D_E/Sample_Test1_T1D_E.R1.fastq.gz read2 Path to R2 FASTQ /data/khanlab/DATA/Sample_Test1_T1D_E/Sample_Test1_T1D_E.R2.fastq.gz sample_captures Capture kit name Sequencing Capture Kits Matched_RNA Matched RNA library (optional) Test1_T1R_T Matched_normal Matched exome normal library (optional) Test1_N1D_E Diagnosis Patient diagnosis Glioma casename Case name NCI-Test1 type Data type tumor_RNA, tumor_DNA, normal_DNA, etc. FCID Flowcell ID (optional) ACJ678349 Genome Genome hg19 or mm39 <p>Example Input csv:</p> sample library read1 read2 sample_captures Diagnosis Matched_RNA Matched_normal casename type FCID Genome Test8 Test5_T1D_E /data/khanlab/projects/fastq/Test5_T1D_E_R1.fastq.gz /data/khanlab/projects/fastq/Test5_T1D_E_R2.fastq.gz clin.ex.v1 Osteosarcoma Test8_N2D_E NFtest0523 tumor_DNA AWXYNH2 hg19 Test8 Test8_N2D_E /data/khanlab/projects/fastq/Test8_N2D_E_R1.fastq.gz /data/khanlab/projects/fastq/Test8_N2D_E_R2.fastq.gz clin.ex.v1 Osteosarcoma NFtest0523 normal_DNA AWXYNH2 hg19"}]}